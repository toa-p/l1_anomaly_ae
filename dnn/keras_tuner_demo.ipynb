{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b40e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  Tesla P100-PCIE-12GB, compute capability 6.0\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "Using MPL HEP for ROOT style formating\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import gc\n",
    "import logging\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "\n",
    "# import setGPU\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "tsk = tfmot.sparsity.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from tensorflow.keras.layers import (\n",
    "    Lambda,\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    AveragePooling2D,\n",
    "    MaxPooling2D,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    "    Conv2DTranspose,\n",
    "    BatchNormalization,\n",
    "    Flatten,\n",
    "    Reshape,\n",
    "    Activation,\n",
    "    ReLU,\n",
    "    LeakyReLU,\n",
    "    Dropout,\n",
    "    Concatenate,\n",
    "    Cropping1D,\n",
    "    Layer,\n",
    "    )\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorboard import program\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import mplhep as hep\n",
    "    hep.style.use(hep.style.ROOT)\n",
    "    print(\"Using MPL HEP for ROOT style formating\")\n",
    "except:\n",
    "    print(\"Instal MPL HEP for style formating\")\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[\"#DB4437\", \"#4285F4\", \"#F4B400\", \"#0F9D58\", \"purple\", \"goldenrod\", \"peru\", \"coral\",\"turquoise\",'gray','navy','m','darkgreen','fuchsia','steelblue']) \n",
    "\n",
    "from autoencoder_classes import AE,VAE\n",
    "from neptunecontrib.monitoring.keras import NeptuneMonitor\n",
    "from losses import mse_split_loss, radius, kl_loss\n",
    "from functions import make_mse_loss_numpy\n",
    "from data_preprocessing import prepare_data\n",
    "from model import build_AE, build_VAE, Sampling\n",
    "\n",
    "def return_total_loss(loss, bsm_t, bsm_pred):\n",
    "    total_loss = loss(bsm_t, bsm_pred.astype(np.float32))\n",
    "    return total_loss\n",
    "\n",
    "from qkeras.quantizers import quantized_bits\n",
    "from keras.utils import tf_utils\n",
    "quantize=False\n",
    "\n",
    "import time\n",
    "ktuner_results = f\"{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6721b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(inputs, outputs):\n",
    "    # remove last dimension\n",
    "    inputs = tf.reshape(inputs, (tf.shape(inputs)[0],19,3))\n",
    "    outputs = tf.reshape(outputs, (tf.shape(outputs)[0],19,3))\n",
    "    \n",
    "    mask0 = tf.math.not_equal(inputs[:,:,0],0)\n",
    "    mask1 = tf.math.not_equal(inputs[:,:,1],0)\n",
    "    mask2 = tf.math.not_equal(inputs[:,:,2],0)\n",
    "    mask = tf.math.logical_and(mask0, mask1)\n",
    "    mask = tf.math.logical_and(mask, mask2)\n",
    "    # tf.print(mask)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = tf.reshape(mask, (tf.shape(mask)[0],19,1))\n",
    "\n",
    "    # remove zero entries\n",
    "    loss = reco_scale*tf.reduce_mean(tf.square(inputs[:,:,:]-outputs[:,:,:])*mask)\n",
    "    return loss\n",
    "\n",
    "def mse_loss_numpy(inputs, outputs):\n",
    "    # remove last dimension\n",
    "    inputs = np.reshape(inputs, (inputs.shape[0],19,3))\n",
    "    outputs = np.reshape(outputs, (outputs.shape[0],19,3))\n",
    "    \n",
    "    mask0 = inputs[:,:,0]!=0\n",
    "    mask1 = inputs[:,:,1]!=0\n",
    "    mask2 = inputs[:,:,2]!=0\n",
    "    mask = (mask0 + mask1 + mask2)*1\n",
    "    mask = np.reshape(mask, (mask.shape[0],19,1))\n",
    "    inputs = inputs*mask\n",
    "    outputs = outputs*mask\n",
    "\n",
    "    # remove zero entries\n",
    "    loss = np.mean(np.square(inputs.reshape(inputs.shape[0],57)-outputs.reshape(outputs.shape[0],57)),axis=1)\n",
    "    return loss\n",
    "\n",
    "def radius(mean, logvar):\n",
    "    sigma = np.sqrt(np.exp(logvar))\n",
    "    radius = mean*mean/sigma/sigma\n",
    "    return np.sum(radius, axis=-1)\n",
    "\n",
    "def kl_loss(mu, logvar, beta=None):\n",
    "    kl_loss = 1 + logvar - np.square(mu) - np.exp(logvar)\n",
    "    kl_loss = np.mean(kl_loss, axis=-1) # mean over latent dimensions\n",
    "    kl_loss *= -0.5\n",
    "    if beta!=None: return beta*kl_loss\n",
    "    else: return kl_loss\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def total_objective(vae, output):\n",
    "    \n",
    "    for key in output.keys():\n",
    "        Y_predict, z_mean , z_logvar = vae.predict(output[key]['target'].reshape(output[key]['target'].shape[0],57),batch_size=1024*4,return_latent=True)\n",
    "        Y_predict = Y_predict.reshape(Y_predict.shape[0],19,3)\n",
    "        output[key]['reco_loss'] = mse_loss_numpy(output[key]['target'], Y_predict)\n",
    "        output[key]['kl_loss'] = kl_loss(z_mean, z_logvar)\n",
    "        output[key]['total_loss'] = output[key]['reco_loss'] + output[key]['kl_loss']\n",
    "    \n",
    "    qcd = output['ZeroBias']['target']\n",
    "    bsm = output['haa4b_ma15_powheg']['target']\n",
    "\n",
    "    total_qcd = output['ZeroBias']['total_loss']\n",
    "    total_bsm = output['haa4b_ma15_powheg']['total_loss']\n",
    "\n",
    "    total_true_val = np.concatenate((np.ones(total_bsm.shape[0]), np.zeros(total_qcd.shape[0])))\n",
    "    total_pred_val = np.nan_to_num(np.concatenate((total_bsm, total_qcd)))\n",
    "\n",
    "    total_fpr_loss, total_tpr_loss, total_threshold_loss = roc_curve(total_true_val, total_pred_val)\n",
    "    total_objective = np.interp(10**(-5), total_fpr_loss, total_tpr_loss)\n",
    "\n",
    "    return total_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58eb9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hp):\n",
    "    input_shape=57\n",
    "    inputs = keras.Input(shape=(input_shape,))\n",
    "    x = layers.Dense(hp.Int(\"inputs\",16,256,32),kernel_initializer='lecun_uniform', activation='relu')(inputs)\n",
    "    \n",
    "    for i in range(hp.Int(\"n_encoder_layers\",1, 5)):\n",
    "        x = layers.Dense(hp.Int(\"encoder_layer_width\",16,256,32),kernel_initializer='lecun_uniform', activation='relu')(x)\n",
    "    \n",
    "    z_width = hp.Int(\"latent_dim_width\",2,12,1)\n",
    "    \n",
    "    z_mean = layers.Dense(z_width,kernel_initializer='zeros')(x)\n",
    "    z_mean = tf.cast(z_mean, tf.float16)\n",
    "    z_logvar = layers.Dense(z_width,kernel_initializer='zeros')(x)\n",
    "    z_logvar = tf.cast(z_logvar, tf.float16)\n",
    "    z = Sampling()([z_mean, z_logvar])\n",
    "    encoder = keras.Model(inputs, [z_mean, z_logvar, z], name=\"encoder\")\n",
    "    encoder.summary()\n",
    "\n",
    "    latent_inputs = keras.Input(hp.Int(\"latent_dim_width\",2,12,1),)\n",
    "    y = layers.Dense(hp.Int(\"layer_width\",16,256,32),kernel_initializer='lecun_uniform', activation='relu')(latent_inputs)\n",
    "    \n",
    "    for i in range(hp.Int(\"n_decoder_layers\",1, 5)):\n",
    "        y = layers.Dense(hp.Int(\"decoder_layer_width\",16,256,32),kernel_initializer='lecun_uniform', activation='relu')(y)\n",
    "    \n",
    "    decoded = layers.Dense(input_shape)(y)\n",
    "    decoder = keras.Model(latent_inputs, decoded, name=\"decoder\")\n",
    "    decoder.summary()\n",
    "    \n",
    "    vae = VAE(encoder, decoder)\n",
    "    obj = total_objective(vae, output)\n",
    "    \n",
    "    vae.compile(optimizer=keras.optimizers.Adam(),\n",
    "                metrics=[mse_loss, kl_loss(z_mean, z_logvar), obj])\n",
    "    \n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0110fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(input_qcd, input_bsm, beta):\n",
    "    \n",
    "    # magic trick to make sure that Lambda function works\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    \n",
    "    global output\n",
    "    output={}\n",
    "    \n",
    "    with h5py.File(input_qcd, 'r') as h5f:\n",
    "        output['ZeroBias'] = {}\n",
    "    \n",
    "        data = np.array(h5f['full_data_cyl'][:events], dtype=np.float16)\n",
    "        ET = np.array(h5f['ET'][:events], dtype=np.float16)\n",
    "        L1bit = np.array(h5f['L1bit'][:events], dtype=np.int8)\n",
    "\n",
    "        #mask saturated ET\n",
    "        mask_ET = ET<2047.5\n",
    "        ET = ET[mask_ET]\n",
    "        data = data[mask_ET]\n",
    "        L1bit = L1bit[mask_ET]\n",
    "    \n",
    "        #mask saturated PT\n",
    "        mask_0  = data[:,0,0]<2047.5\n",
    "        mask_1_9  = data[:,1:9,0]<255.5\n",
    "        mask_9_20  = data[:,9:20,0]<1023.5\n",
    "        mask = np.concatenate((mask_0[:,np.newaxis],mask_1_9,mask_9_20),axis=1)*1\n",
    "        data = data*mask[:,:,np.newaxis]\n",
    "\n",
    "        pt = np.copy(data[:,:,0])\n",
    "        eta = np.copy(data[:,:,1])\n",
    "        phi = np.copy(data[:,:,2])\n",
    "    \n",
    "        data[:,:,0] = pt*np.cos(phi)\n",
    "        data[:,:,1] = pt*np.sin(phi)\n",
    "        data[:,:,2] = pt*np.sinh(eta)\n",
    "        data_target = np.copy(data)\n",
    "\n",
    "        del pt, eta, phi, mask_ET, mask_0, mask_1_9, mask_9_20, mask\n",
    "    \n",
    "        if(norm=='ET'):\n",
    "            data_target[:,:,:] = data[:,:,:]/ET[:,None,None]\n",
    "            std_xy = (np.std(data_target[:,:,0])+np.std(data_target[:,:,1]))/2\n",
    "            std_z = np.std(data_target[:,:,2])\n",
    "            data_target[:,:,2] = data_target[:,:,2]*(std_xy/std_z)\n",
    "        elif(norm=='std'):\n",
    "            mean_qcd = np.mean(data_target, axis=0)\n",
    "            std_qcd = np.std(data_target, axis=0)\n",
    "            data_target = (data_target[:,:,:] - mean_qcd[None,:,:])/std_qcd[None,:,:]\n",
    "\n",
    "            # mean_qcd = np.array([np.mean(data_target[:,:,0]),np.mean(data_target[:,:,1]),np.mean(data_target[:,1:20,2])])\n",
    "            # std_qcd = np.array([np.std(data_target[:,:,0]),np.std(data_target[:,:,1]),np.std(data_target[:,1:20,2])])\n",
    "            # data_target[:,:,0] = (data_target[:,:,0]-mean_qcd[0])/std_qcd[0]\n",
    "            # data_target[:,:,1] = (data_target[:,:,1]-mean_qcd[1])/std_qcd[1]\n",
    "            # data_target[:,:,2] = (data_target[:,:,2]-mean_qcd[2])/std_qcd[2] \n",
    "            data_target[:,0,2] = 0\n",
    "        else:\n",
    "            data_target[:,0,:] = data[:,0,:]/2048\n",
    "            data_target[:,1:9,:] = data[:,1:9,:]/256\n",
    "            data_target[:,9:20,:] = data[:,9:20,:]/1024\n",
    "        \n",
    "\n",
    "        X_train, output['ZeroBias']['data'], Y_train, output['ZeroBias']['target'], _ , output['ZeroBias']['ET'], _ ,output['ZeroBias']['L1bit'] =  train_test_split( data, data_target, ET,L1bit, test_size=0.5)\n",
    "\n",
    "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "        Y_train = Y_train.reshape(Y_train.shape[0], Y_train.shape[1]*Y_train.shape[2])\n",
    "\n",
    "        del data, data_target, ET, L1bit\n",
    "        \n",
    "    with h5py.File(input_bsm,'r') as h5f2:\n",
    "        for key in h5f2.keys():\n",
    "            if('TT' not in key[:2]) and ('haa4b_ma15_powheg' not in key) and ('GluGluToHHTo4B_cHHH1' not in key): continue\n",
    "            if len(h5f2[key].shape) < 3: continue\n",
    "            \n",
    "            output[str(key)] = {}\n",
    "            output[str(key)]['data'] = np.array(h5f2[str(key)][:events,:,:],dtype=np.float16)\n",
    "            output[str(key)]['ET'] = np.array(h5f2[str(key)+'_ET'][:events],dtype=np.float16)\n",
    "            output[str(key)]['L1bit'] = np.array(h5f2[str(key)+'_l1bit'][:events],dtype=np.int8)\n",
    "\n",
    "            #mask saturated ET\n",
    "            mask_ET = output[str(key)]['ET']<2047.5\n",
    "            output[str(key)]['ET'] = output[str(key)]['ET'][mask_ET]\n",
    "            output[str(key)]['data'] = output[str(key)]['data'][mask_ET]\n",
    "            output[str(key)]['L1bit'] = output[str(key)]['L1bit'][mask_ET]\n",
    "        \n",
    "            #mask saturated PT\n",
    "            mask_0  = output[str(key)]['data'][:,0,0]<2047.5\n",
    "            mask_1_9  = output[str(key)]['data'][:,1:9,0]<255.5\n",
    "            mask_9_20  = output[str(key)]['data'][:,9:20,0]<1023.5\n",
    "            mask = np.concatenate((mask_0[:,np.newaxis],mask_1_9,mask_9_20),axis=1)*1\n",
    "            output[str(key)]['data'] = output[str(key)]['data']*mask[:,:,np.newaxis]\n",
    "\n",
    "            pt = np.copy(output[str(key)]['data'][:,:,0])\n",
    "            eta = np.copy(output[str(key)]['data'][:,:,1])\n",
    "            phi = np.copy(output[str(key)]['data'][:,:,2])\n",
    "        \n",
    "            output[str(key)]['data'][:,:,0] = pt*np.cos(phi)\n",
    "            output[str(key)]['data'][:,:,1] = pt*np.sin(phi)\n",
    "            output[str(key)]['data'][:,:,2] = pt*np.sinh(eta)\n",
    "\n",
    "            del pt, eta, phi, mask_ET, mask_0, mask_1_9, mask_9_20, mask\n",
    "\n",
    "\n",
    "            output[str(key)]['target'] = np.copy(output[str(key)]['data'])\n",
    "            if(norm=='ET'):\n",
    "                output[str(key)]['target'] = output[str(key)]['data']/output[str(key)]['ET'][:,None,None]\n",
    "                output[str(key)]['target'][:,:,2] = output[str(key)]['target'][:,:,2]*(std_xy/std_z)\n",
    "            elif(norm=='std'):\n",
    "                output[str(key)]['target'] = (output[str(key)]['target'] - mean_qcd[None,:,:])/std_qcd[None,:,:]\n",
    "                # output[str(key)]['target'][:,:,0]= (output[str(key)]['data'][:,:,0]-mean_qcd[0])/std_qcd[0]\n",
    "                # output[str(key)]['target'][:,:,1]= (output[str(key)]['data'][:,:,1]-mean_qcd[1])/std_qcd[1]\n",
    "                # output[str(key)]['target'][:,:,2]= (output[str(key)]['data'][:,:,2]-mean_qcd[2])/std_qcd[2]\n",
    "                output[str(key)]['target'][:,0,2] = 0\n",
    "            elif(norm=='max_PT'):\n",
    "                output[str(key)]['target'][:,0,:] = output[str(key)]['data'][:,0,:]/2048\n",
    "                output[str(key)]['target'][:,1:9,:] = output[str(key)]['data'][:,1:9,:]/256\n",
    "                output[str(key)]['target'][:,9:20,:] = output[str(key)]['data'][:,9:20,:]/1024\n",
    "        \n",
    "    ktuner = kt.BayesianOptimization(\n",
    "            hypermodel=make_model,\n",
    "            objective = kt.Objective('val_total_objective', direction='min'),\n",
    "            max_trials = 1,\n",
    "            executions_per_trial = 3,\n",
    "            directory = ktuner_results)\n",
    "    \n",
    "    ktuner.search(x=X_train,\n",
    "                 y=Y_train,\n",
    "                 epochs=5,\n",
    "                 batch_size=1024,\n",
    "                 validation_split=0.2,\n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=5)])\n",
    "    \n",
    "    with open(f\"ktuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(ktuner, f)\n",
    "    \n",
    "    ktuner.results_summary()\n",
    "    \n",
    "    logging.info('Get the optimal hyperparameters')\n",
    "    best_hps = ktuner.get_best_hyperparameters(num_trials=5)[0]\n",
    "    logging.info('Getting and printing best hyperparameters!')\n",
    "    print(best_hps)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51cb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_hardqcd=\"/eos/uscms/store/group/lpctrig/jngadiub/L1TNtupleRun3-h5-extended-v2/QCD_preprocessed.h5\"\n",
    "input_qcd=\"/eos/uscms/store/group/lpctrig/jngadiub/L1TNtupleRun3-ZB-h5-extended-v2/ZB_preprocessed.h5\"\n",
    "input_bsm = \"/eos/uscms/store/group/lpctrig/jngadiub/L1TNtupleRun3-h5-extended-v2-120X/BSM_preprocessed.h5\"\n",
    "events=500000\n",
    "norm = 'std'\n",
    "beta = 0.8\n",
    "reco_scale = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c5ced3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_195759/1538566277.py\", line 57, in call  *\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_qcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_bsm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36moptimization\u001b[0;34m(input_qcd, input_bsm, beta)\u001b[0m\n\u001b[1;32m    115\u001b[0m             output[\u001b[38;5;28mstr\u001b[39m(key)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m9\u001b[39m,:] \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;28mstr\u001b[39m(key)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m9\u001b[39m,:]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    116\u001b[0m             output[\u001b[38;5;28mstr\u001b[39m(key)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m9\u001b[39m:\u001b[38;5;241m20\u001b[39m,:] \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;28mstr\u001b[39m(key)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m9\u001b[39m:\u001b[38;5;241m20\u001b[39m,:]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\n\u001b[0;32m--> 118\u001b[0m ktuner \u001b[38;5;241m=\u001b[39m \u001b[43mkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBayesianOptimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mObjective\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_total_objective\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutions_per_trial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mktuner_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m ktuner\u001b[38;5;241m.\u001b[39msearch(x\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[1;32m    126\u001b[0m              y\u001b[38;5;241m=\u001b[39mY_train,\n\u001b[1;32m    127\u001b[0m              epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    128\u001b[0m              batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m    129\u001b[0m              validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m    130\u001b[0m              callbacks\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)])\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mktuner_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/uscms_data/d3/tphan/miniforge3/envs/l1ad/lib/python3.9/site-packages/keras_tuner/tuners/bayesian.py:413\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     hypermodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    401\u001b[0m ):\n\u001b[1;32m    402\u001b[0m     oracle \u001b[38;5;241m=\u001b[39m BayesianOptimizationOracle(\n\u001b[1;32m    403\u001b[0m         objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m    404\u001b[0m         max_trials\u001b[38;5;241m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m         allow_new_entries\u001b[38;5;241m=\u001b[39mallow_new_entries,\n\u001b[1;32m    412\u001b[0m     )\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBayesianOptimization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uscms_data/d3/tphan/miniforge3/envs/l1ad/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:111\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner\u001b[38;5;241m.\u001b[39mrun_trial:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hypermodel` if the user defines the search space in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `HyperModel` instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m     )\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTuner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(oracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(oracle\u001b[38;5;241m.\u001b[39mobjective) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-objective is not supported, found: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    123\u001b[0m             oracle\u001b[38;5;241m.\u001b[39mobjective\n\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m     )\n",
      "File \u001b[0;32m/uscms_data/d3/tphan/miniforge3/envs/l1ad/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:103\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m logger\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display \u001b[38;5;241m=\u001b[39m tuner_utils\u001b[38;5;241m.\u001b[39mDisplay(oracle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate_initial_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mand\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tuner_fname()):\n\u001b[1;32m    106\u001b[0m     tf\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReloading Tuner from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tuner_fname())\n\u001b[1;32m    108\u001b[0m     )\n",
      "File \u001b[0;32m/uscms_data/d3/tphan/miniforge3/envs/l1ad/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:132\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m scopes_once_active \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Update the recored scopes.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conditions \u001b[38;5;129;01min\u001b[39;00m hp\u001b[38;5;241m.\u001b[39mactive_scopes:\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mmake_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m     13\u001b[0m z_logvar \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(z_width,kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     14\u001b[0m z_logvar \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(z_logvar, tf\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m---> 15\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mSampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_logvar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m encoder \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs, [z_mean, z_logvar, z], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m encoder\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/uscms_data/d3/tphan/miniforge3/envs/l1ad/lib/python3.9/site-packages/keras/engine/base_layer_v1.py:765\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    763\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    764\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m--> 765\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOperatorNotAllowedInGraphError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou are attempting to use Python control \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    769\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflow in a layer that was not declared to be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    770\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic. Pass `dynamic=True` to the class \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    771\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstructor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEncountered error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    772\u001b[0m                   \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/uscms_data/d3/tphan/miniforge3/envs/l1ad/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:699\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    700\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_195759/1538566277.py\", line 57, in call  *\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "optimization(input_qcd, input_bsm, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b288306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

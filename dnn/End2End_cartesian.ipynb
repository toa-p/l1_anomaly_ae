{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4acc2d9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mplhep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmplhep\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhep\u001b[39;00m\n\u001b[1;32m     29\u001b[0m hep\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(hep\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mROOT)\n\u001b[1;32m     30\u001b[0m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.prop_cycle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mcycler(color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#DB4437\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#4285F4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#F4B400\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#0F9D58\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoldenrod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoral\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mturquoise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnavy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarkgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuchsia\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteelblue\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mplhep'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, BatchNormalization, Activation, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorboard import program\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "hep.style.use(hep.style.ROOT)\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[\"#DB4437\", \"#4285F4\", \"#F4B400\", \"#0F9D58\", \"purple\", \"goldenrod\", \"peru\", \"coral\",\"turquoise\",'gray','navy','m','darkgreen','fuchsia','steelblue']) \n",
    "# from autoencoder_classes import AE,VAE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from neptunecontrib.monitoring.keras import NeptuneMonitor\n",
    "# from losses import mse_split_loss, radius, kl_loss\n",
    "# from functions import make_mse_loss_numpy, save_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# from data_preprocessing import prepare_data\n",
    "# from model import build_AE, build_VAE, build_QVAE\n",
    "\n",
    "\n",
    "def return_total_loss(loss, bsm_t, bsm_pred):\n",
    "    total_loss = loss(bsm_t, bsm_pred.astype(np.float32))\n",
    "    return total_loss\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "tsk = tfmot.sparsity.keras\n",
    "\n",
    "from qkeras.quantizers import quantized_bits\n",
    "\n",
    "from keras.utils import tf_utils\n",
    "\n",
    "quantize=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_hardqcd=\"/eos/uscms/store/group/lpctrig/jngadiub/L1TNtupleRun3-h5-extended-v2/QCD_preprocessed.h5\"\n",
    "input_qcd=\"/eos/uscms/store/group/lpctrig/jngadiub/L1TNtupleRun3-ZB-h5-extended-v2/ZB5_preprocessed.h5\"\n",
    "input_bsm = \"/eos/uscms/store/group/lpctrig/jngadiub/L1TNtupleRun3-h5-extended-v2-120X/BSM_preprocessed.h5\"\n",
    "events=500000\n",
    "norm = 'std'\n",
    "output = {}\n",
    "\n",
    "\n",
    "with h5py.File(input_qcd, 'r') as h5f:\n",
    "    output['ZeroBias'] = {}\n",
    "    \n",
    "    data = np.array(h5f['full_data_cyl'][:events], dtype=np.float16)\n",
    "    ET = np.array(h5f['ET'][:events], dtype=np.float16)\n",
    "    L1bit = np.array(h5f['L1bit'][:events], dtype=np.int8)\n",
    "\n",
    "    #mask saturated ET\n",
    "    mask_ET = ET<2047.5\n",
    "    ET = ET[mask_ET]\n",
    "    data = data[mask_ET]\n",
    "    L1bit = L1bit[mask_ET]\n",
    "    \n",
    "    #mask saturated PT\n",
    "    mask_0  = data[:,0,0]<2047.5\n",
    "    mask_1_9  = data[:,1:9,0]<255.5\n",
    "    mask_9_20  = data[:,9:20,0]<1023.5\n",
    "    mask = np.concatenate((mask_0[:,np.newaxis],mask_1_9,mask_9_20),axis=1)*1\n",
    "    data = data*mask[:,:,np.newaxis]\n",
    "\n",
    "    pt = np.copy(data[:,:,0])\n",
    "    eta = np.copy(data[:,:,1])\n",
    "    phi = np.copy(data[:,:,2])\n",
    "    \n",
    "    data[:,:,0] = pt*np.cos(phi)\n",
    "    data[:,:,1] = pt*np.sin(phi)\n",
    "    data[:,:,2] = pt*np.sinh(eta)\n",
    "    data_target = np.copy(data)\n",
    "\n",
    "    del pt, eta, phi, mask_ET, mask_0, mask_1_9, mask_9_20, mask\n",
    "\n",
    "    \n",
    "    # print(h5f.keys())\n",
    "\n",
    "    if(norm=='ET'):\n",
    "        data_target[:,:,:] = data[:,:,:]/ET[:,None,None]\n",
    "        std_xy = (np.std(data_target[:,:,0])+np.std(data_target[:,:,1]))/2\n",
    "        std_z = np.std(data_target[:,:,2])\n",
    "        data_target[:,:,2] = data_target[:,:,2]*(std_xy/std_z)\n",
    "    elif(norm=='std'):\n",
    "        mean_qcd = np.mean(data_target, axis=0)\n",
    "        std_qcd = np.std(data_target, axis=0)\n",
    "        data_target = (data_target[:,:,:] - mean_qcd[None,:,:])/std_qcd[None,:,:]\n",
    "\n",
    "        # mean_qcd = np.array([np.mean(data_target[:,:,0]),np.mean(data_target[:,:,1]),np.mean(data_target[:,1:20,2])])\n",
    "        # std_qcd = np.array([np.std(data_target[:,:,0]),np.std(data_target[:,:,1]),np.std(data_target[:,1:20,2])])\n",
    "        # data_target[:,:,0] = (data_target[:,:,0]-mean_qcd[0])/std_qcd[0]\n",
    "        # data_target[:,:,1] = (data_target[:,:,1]-mean_qcd[1])/std_qcd[1]\n",
    "        # data_target[:,:,2] = (data_target[:,:,2]-mean_qcd[2])/std_qcd[2] \n",
    "        data_target[:,0,2] = 0\n",
    "    else:\n",
    "        data_target[:,0,:] = data[:,0,:]/2048\n",
    "        data_target[:,1:9,:] = data[:,1:9,:]/256\n",
    "        data_target[:,9:20,:] = data[:,9:20,:]/1024\n",
    "        \n",
    "\n",
    "    X_train, output['ZeroBias']['data'], Y_train, output['ZeroBias']['target'], _ , output['ZeroBias']['ET'], _ ,output['ZeroBias']['L1bit'] =  train_test_split( data, data_target, ET,L1bit, test_size=0.5)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "    Y_train = Y_train.reshape(Y_train.shape[0], Y_train.shape[1]*Y_train.shape[2])\n",
    "\n",
    "del data, data_target, ET, L1bit\n",
    "\n",
    "\n",
    "with h5py.File(input_hardqcd, 'r') as h5f:\n",
    "    output['QCD'] = {}\n",
    "    \n",
    "    data = np.array(h5f['full_data_cyl'][:events], dtype=np.float16)\n",
    "    ET = np.array(h5f['ET'][:events], dtype=np.float16)\n",
    "    L1bit = np.array(h5f['L1bit'][:events], dtype=np.int8)\n",
    "\n",
    "    #mask saturated ET\n",
    "    mask_ET = ET<2047.5\n",
    "    ET = ET[mask_ET]\n",
    "    data = data[mask_ET]\n",
    "    L1bit = L1bit[mask_ET]\n",
    "    \n",
    "    #mask saturated PT\n",
    "    mask_0  = data[:,0,0]<2047.5\n",
    "    mask_1_9  = data[:,1:9,0]<255.5\n",
    "    mask_9_20  = data[:,9:20,0]<1023.5\n",
    "    mask = np.concatenate((mask_0[:,np.newaxis],mask_1_9,mask_9_20),axis=1)*1\n",
    "    data = data*mask[:,:,np.newaxis]\n",
    "\n",
    "    pt = np.copy(data[:,:,0])\n",
    "    eta = np.copy(data[:,:,1])\n",
    "    phi = np.copy(data[:,:,2])\n",
    "    \n",
    "    data[:,:,0] = pt*np.cos(phi)\n",
    "    data[:,:,1] = pt*np.sin(phi)\n",
    "    data[:,:,2] = pt*np.sinh(eta)\n",
    "    data_target = np.copy(data)\n",
    "\n",
    "    del pt, eta, phi, mask_ET, mask_0, mask_1_9, mask_9_20, mask\n",
    "\n",
    "    \n",
    "    # print(h5f.keys())\n",
    "\n",
    "    if(norm=='ET'):\n",
    "        data_target[:,:,:] = data[:,:,:]/ET[:,None,None]\n",
    "        data_target[:,:,2] = data_target[:,:,2]*(std_xy/std_z)\n",
    "    elif(norm=='std'):\n",
    "\n",
    "        data_target = (data_target[:,:,:] - mean_qcd[None,:,:])/std_qcd[None,:,:]\n",
    "        # data_target[:,:,0] = (data_target[:,:,0]-mean_qcd[0])/std_qcd[0]\n",
    "        # data_target[:,:,1] = (data_target[:,:,1]-mean_qcd[1])/std_qcd[1]\n",
    "        # data_target[:,:,2] = (data_target[:,:,2]-mean_qcd[2])/std_qcd[2] \n",
    "        data_target[:,0,2] = 0\n",
    "    else:\n",
    "        data_target[:,0,:] = data[:,0,:]/2048\n",
    "        data_target[:,1:9,:] = data[:,1:9,:]/256\n",
    "        data_target[:,9:20,:] = data[:,9:20,:]/1024\n",
    "        \n",
    "\n",
    "    output['QCD']['data'], output['QCD']['target'], output['QCD']['ET'],output['QCD']['L1bit'] =   data, data_target, ET,L1bit\n",
    "\n",
    "del data, data_target, ET, L1bit\n",
    "\n",
    "with h5py.File(input_bsm,'r') as h5f2:\n",
    "    for key in h5f2.keys():\n",
    "        if('TT' not in key[:2]) and ('haa4b_ma15_powheg' not in key) and ('GluGluToHHTo4B_cHHH1' not in key): continue\n",
    "        if len(h5f2[key].shape) < 3: continue\n",
    "        print(key)\n",
    "        output[str(key)] = {}\n",
    "        output[str(key)]['data'] = np.array(h5f2[str(key)][:events,:,:],dtype=np.float16)\n",
    "        output[str(key)]['ET'] = np.array(h5f2[str(key)+'_ET'][:events],dtype=np.float16)\n",
    "        output[str(key)]['L1bit'] = np.array(h5f2[str(key)+'_l1bit'][:events],dtype=np.int8)\n",
    "\n",
    "        #mask saturated ET\n",
    "        mask_ET = output[str(key)]['ET']<2047.5\n",
    "        output[str(key)]['ET'] = output[str(key)]['ET'][mask_ET]\n",
    "        output[str(key)]['data'] = output[str(key)]['data'][mask_ET]\n",
    "        output[str(key)]['L1bit'] = output[str(key)]['L1bit'][mask_ET]\n",
    "        \n",
    "        #mask saturated PT\n",
    "        mask_0  = output[str(key)]['data'][:,0,0]<2047.5\n",
    "        mask_1_9  = output[str(key)]['data'][:,1:9,0]<255.5\n",
    "        mask_9_20  = output[str(key)]['data'][:,9:20,0]<1023.5\n",
    "        mask = np.concatenate((mask_0[:,np.newaxis],mask_1_9,mask_9_20),axis=1)*1\n",
    "        output[str(key)]['data'] = output[str(key)]['data']*mask[:,:,np.newaxis]\n",
    "\n",
    "        pt = np.copy(output[str(key)]['data'][:,:,0])\n",
    "        eta = np.copy(output[str(key)]['data'][:,:,1])\n",
    "        phi = np.copy(output[str(key)]['data'][:,:,2])\n",
    "        \n",
    "        output[str(key)]['data'][:,:,0] = pt*np.cos(phi)\n",
    "        output[str(key)]['data'][:,:,1] = pt*np.sin(phi)\n",
    "        output[str(key)]['data'][:,:,2] = pt*np.sinh(eta)\n",
    "\n",
    "        del pt, eta, phi, mask_ET, mask_0, mask_1_9, mask_9_20, mask\n",
    "\n",
    "\n",
    "        output[str(key)]['target'] = np.copy(output[str(key)]['data'])\n",
    "        if(norm=='ET'):\n",
    "            output[str(key)]['target'] = output[str(key)]['data']/output[str(key)]['ET'][:,None,None]\n",
    "            output[str(key)]['target'][:,:,2] = output[str(key)]['target'][:,:,2]*(std_xy/std_z)\n",
    "        elif(norm=='std'):\n",
    "            output[str(key)]['target'] = (output[str(key)]['target'] - mean_qcd[None,:,:])/std_qcd[None,:,:]\n",
    "            # output[str(key)]['target'][:,:,0]= (output[str(key)]['data'][:,:,0]-mean_qcd[0])/std_qcd[0]\n",
    "            # output[str(key)]['target'][:,:,1]= (output[str(key)]['data'][:,:,1]-mean_qcd[1])/std_qcd[1]\n",
    "            # output[str(key)]['target'][:,:,2]= (output[str(key)]['data'][:,:,2]-mean_qcd[2])/std_qcd[2]\n",
    "            output[str(key)]['target'][:,0,2] = 0\n",
    "        elif(norm=='max_PT'):\n",
    "            output[str(key)]['target'][:,0,:] = output[str(key)]['data'][:,0,:]/2048\n",
    "            output[str(key)]['target'][:,1:9,:] = output[str(key)]['data'][:,1:9,:]/256\n",
    "            output[str(key)]['target'][:,9:20,:] = output[str(key)]['data'][:,9:20,:]/1024\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249287f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "_=plt.hist(output['ZeroBias']['data'][:,1:9,0].flatten(),bins=100,label=r'$\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(np.mean(output['ZeroBias']['data'][:,1:9,0]),np.std(output['ZeroBias']['data'][:,1:9,0])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "_=plt.hist(output['ZeroBias']['data'][:,1:9,1].flatten(),bins=100,label=r'$\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(np.mean(output['ZeroBias']['data'][:,1:9,1]),np.std(output['ZeroBias']['data'][:,1:9,1])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "_=plt.hist(output['ZeroBias']['data'][:,1:9,2].flatten(),bins=100,label=r'$\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(np.mean(output['ZeroBias']['data'][:,1:9,2]),np.std(output['ZeroBias']['data'][:,1:9,2])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_=plt.hist(output['ZeroBias']['target'][:,:,0].flatten(),bins=100,label=r'$\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(np.mean(output['ZeroBias']['target'][:,:,0]),np.std(output['ZeroBias']['target'][:,:,0])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "_=plt.hist(output['ZeroBias']['target'][:,:,1].flatten(),bins=100,label=r'$\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(np.mean(output['ZeroBias']['target'][:,:,1]),np.std(output['ZeroBias']['target'][:,:,1])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "_=plt.hist(output['ZeroBias']['target'][:,:,2].flatten(),bins=100,label=r'$\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(np.mean(output['ZeroBias']['target'][:,:,2]),np.std(output['ZeroBias']['target'][:,:,2])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df07e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-1024,1024,100)\n",
    "for key in output.keys():\n",
    "    _=plt.hist(output[key]['data'][:,:,0].flatten(),bins=bins,label=r'{} $\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(key.split('_')[0],np.mean(output[key]['data'][:,:,0]),np.std(output[key]['data'][:,:,0])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$p_x$')\n",
    "plt.legend(fontsize='x-small',loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "for key in output.keys():\n",
    "    _=plt.hist(output[key]['data'][:,:,1].flatten(),bins=bins,label=r'{} $\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(key.split('_')[0],np.mean(output[key]['data'][:,:,1]),np.std(output[key]['data'][:,:,1])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$p_y$')\n",
    "plt.legend(fontsize='x-small',loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bins = np.linspace(-7500,7500,100)\n",
    "for key in output.keys():\n",
    "    _=plt.hist(output[key]['data'][:,:,2].flatten(),bins=bins,label=r'{} $\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(key.split('_')[0],np.mean(output[key]['data'][:,:,2]),np.std(output[key]['data'][:,:,2])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$p_z$')\n",
    "plt.legend(fontsize='x-small',loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-1,1,100)\n",
    "for key in output.keys():\n",
    "    _=plt.hist(output[key]['target'][:,:,0].flatten(),bins=bins,label=r'{} $\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(key.split('_')[0],np.mean(output[key]['target'][:,:,0]),np.std(output[key]['target'][:,:,0])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$\\hat{p}_x$')\n",
    "plt.legend(fontsize='x-small',loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "for key in output.keys():\n",
    "    _=plt.hist(output[key]['target'][:,:,1].flatten(),bins=bins,label=r'{} $\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(key.split('_')[0],np.mean(output[key]['target'][:,:,1]),np.std(output[key]['target'][:,:,1])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$\\hat{p}_y$')\n",
    "plt.legend(fontsize='x-small',loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "for key in output.keys():\n",
    "    _=plt.hist(output[key]['target'][:,:,2].flatten(),bins=bins,label=r'{} $\\mu$={:0.3f} $\\sigma$={:0.3f}'.format(key.split('_')[0],np.mean(output[key]['target'][:,:,2]),np.std(output[key]['target'][:,:,2])),histtype='step',density=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$\\hat{p}_z$')\n",
    "plt.legend(fontsize='x-small',loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_scale = 1000\n",
    "beta = 0.8\n",
    "\n",
    "def mse_loss(inputs, outputs):\n",
    "    # remove last dimension\n",
    "    inputs = tf.reshape(inputs, (tf.shape(inputs)[0],19,3))\n",
    "    outputs = tf.reshape(outputs, (tf.shape(outputs)[0],19,3))\n",
    "    \n",
    "    mask0 = tf.math.not_equal(inputs[:,:,0],0)\n",
    "    mask1 = tf.math.not_equal(inputs[:,:,1],0)\n",
    "    mask2 = tf.math.not_equal(inputs[:,:,2],0)\n",
    "    mask = tf.math.logical_and(mask0, mask1)\n",
    "    mask = tf.math.logical_and(mask, mask2)\n",
    "    # tf.print(mask)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = tf.reshape(mask, (tf.shape(mask)[0],19,1))\n",
    "\n",
    "    # remove zero entries\n",
    "    loss = reco_scale*tf.reduce_mean(tf.square(inputs[:,:,:]-outputs[:,:,:])*mask)\n",
    "    return loss\n",
    "\n",
    "def mse_loss_numpy(inputs, outputs):\n",
    "    # remove last dimension\n",
    "    inputs = np.reshape(inputs, (inputs.shape[0],19,3))\n",
    "    outputs = np.reshape(outputs, (outputs.shape[0],19,3))\n",
    "    \n",
    "    mask0 = inputs[:,:,0]!=0\n",
    "    mask1 = inputs[:,:,1]!=0\n",
    "    mask2 = inputs[:,:,2]!=0\n",
    "    mask = (mask0 + mask1 + mask2)*1\n",
    "    mask = np.reshape(mask, (mask.shape[0],19,1))\n",
    "    inputs = inputs*mask\n",
    "    outputs = outputs*mask\n",
    "\n",
    "    # remove zero entries\n",
    "    loss = np.mean(np.square(inputs.reshape(inputs.shape[0],57)-outputs.reshape(outputs.shape[0],57)),axis=1)\n",
    "    return loss\n",
    "\n",
    "def radius(mean, logvar):\n",
    "    sigma = np.sqrt(np.exp(logvar))\n",
    "    radius = mean*mean/sigma/sigma\n",
    "    return np.sum(radius, axis=-1)\n",
    "\n",
    "def kl_loss(mu, logvar, beta=None):\n",
    "    kl_loss = 1 + logvar - np.square(mu) - np.exp(logvar)\n",
    "    kl_loss = np.mean(kl_loss, axis=-1) # mean over latent dimensions\n",
    "    kl_loss *= -0.5\n",
    "    if beta!=None: return beta*kl_loss\n",
    "    else: return kl_loss\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.total_val_loss_tracker = keras.metrics.Mean(name=\"total_val_loss\")\n",
    "        self.reconstruction_val_loss_tracker = keras.metrics.Mean(name=\"reconstruction_val_loss\")\n",
    "        self.kl_val_loss_tracker = keras.metrics.Mean(name=\"kl_val_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.total_val_loss_tracker,\n",
    "            self.reconstruction_val_loss_tracker,\n",
    "            self.kl_val_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        data_in, target = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data_in)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = (1-beta)*mse_loss(target, reconstruction) #one value\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = beta*tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        # tf.print(reconstruction_loss,kl_loss)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "   \n",
    "    def test_step(self, data):\n",
    "        data_in, target = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data_in)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = (1-beta)*mse_loss(target, reconstruction) #one value\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = beta*tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.total_val_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_val_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_val_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_val_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_val_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_val_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def predict(self, data_in, batch_size=32, return_latent=False):\n",
    "        # print(data_in)\n",
    "        data_batch = tf.data.Dataset.from_tensor_slices((data_in))\n",
    "        output, z_mean, z_logvar = [],[],[]\n",
    "        for data in data_batch.batch(batch_size):\n",
    "            # print(data.shape)\n",
    "            z_mean_, z_logvar_, z_ = self.encoder(data)\n",
    "            output_ = self.decoder(z_)\n",
    "            output.append(output_)\n",
    "            z_mean.append(z_mean_)\n",
    "            z_logvar.append(z_logvar_)\n",
    "        # print(len(output),len(z_mean),len(z_logvar))\n",
    "        # print(output[0])\n",
    "        output = tf.concat(output,0)\n",
    "        z_mean = tf.concat(z_mean,0)\n",
    "        z_logvar = tf.concat(z_logvar,0)\n",
    "    \n",
    "        if(return_latent):\n",
    "            return tf_utils.sync_to_numpy_or_python_type(output), tf_utils.sync_to_numpy_or_python_type(z_mean), tf_utils.sync_to_numpy_or_python_type(z_logvar)\n",
    "        else:\n",
    "            return tf_utils.sync_to_numpy_or_python_type(output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=4\n",
    "input_shape=57\n",
    "inputs = keras.Input(shape=(input_shape,))\n",
    "x = layers.Dense(32,kernel_initializer='lecun_uniform', activation='relu')(inputs)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(32,kernel_initializer='lecun_uniform', activation='relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "z_mean = layers.Dense(latent_dim,kernel_initializer='zeros')(x)\n",
    "z_logvar = layers.Dense(latent_dim,kernel_initializer='zeros')(x)\n",
    "z = Sampling()([z_mean, z_logvar])\n",
    "encoder = keras.Model(inputs, [z_mean, z_logvar, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "latent_inputs = keras.Input(latent_dim,)\n",
    "y = layers.Dense(16,kernel_initializer='lecun_uniform', activation='relu')(latent_inputs)\n",
    "y = layers.Dense(32,kernel_initializer='lecun_uniform', activation='relu')(y)\n",
    "y = layers.Dense(64,kernel_initializer='lecun_uniform', activation='relu')(y)\n",
    "y = layers.Dense(128,kernel_initializer='lecun_uniform', activation='relu')(y)\n",
    "# y = layers.Dense(256,kernel_initializer='lecun_uniform', activation='relu')(y)\n",
    "decoded = layers.Dense(input_shape)(y)\n",
    "decoder = keras.Model(latent_inputs, decoded, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "callbacks=[]\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss',  factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.1, cooldown=2, min_lr=1e-6))\n",
    "callbacks.append(TerminateOnNaN())\n",
    "# callbacks.append(NeptuneMonitor())\n",
    "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=2, restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b27ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vae.fit(Y_train, Y_train,validation_split=0.2, epochs=500, batch_size=1024, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb412337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot training history\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fdaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot training history\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['kl_loss'], label='train')\n",
    "plt.plot(history.history['val_kl_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in output.keys():\n",
    "    Y_predict, z_mean , z_logvar = vae.predict(output[key]['target'].reshape(output[key]['target'].shape[0],57),batch_size=1024*4,return_latent=True)\n",
    "    Y_predict = Y_predict.reshape(Y_predict.shape[0],19,3)\n",
    "    output[key]['prediction'] = Y_predict\n",
    "    output[key]['reco_loss'] = mse_loss_numpy(output[key]['target'], Y_predict)\n",
    "    output[key]['kl_loss'] = kl_loss(z_mean, z_logvar)\n",
    "    output[key]['radius'] = radius(z_mean, z_logvar)\n",
    "    output[key]['total_loss'] = output[key]['reco_loss'] + output[key]['kl_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074eec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_key='ZeroBias'\n",
    "bins_ = np.linspace(-1,1,100)\n",
    "test = output[bkg_key]['target'][:,1:9,:]\n",
    "test = test.reshape(output[bkg_key]['target'].shape[0]*8,3)\n",
    "mask0 = test[:,0]!=0\n",
    "mask1 = test[:,1]!=0\n",
    "mask2 = test[:,2]!=0\n",
    "mask = mask0 + mask1 + mask2\n",
    "test = test[mask]\n",
    "predict = output[bkg_key]['prediction'][:,1:9,:]\n",
    "predict = predict.reshape(output[bkg_key]['prediction'].shape[0]*8,3)\n",
    "predict = predict[mask]\n",
    "plt.hist(test.flatten(), bins=bins_, alpha=0.5, label='X_test')\n",
    "plt.hist(predict.flatten(), bins=bins_, alpha=0.5, label='X_predict')\n",
    "plt.xlabel('Pi (GeV)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.yscale('log')\n",
    "plt.title('Muon, electon, and photon pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_key='ZeroBias'\n",
    "bins_ = np.linspace(-1,1,100)\n",
    "test = output[bkg_key]['target'][:,9:20,:]\n",
    "test = test.reshape(output[bkg_key]['target'].shape[0]*10,3)\n",
    "mask0 = test[:,0]!=0\n",
    "mask1 = test[:,1]!=0\n",
    "mask2 = test[:,2]!=0\n",
    "mask = mask0 + mask1 + mask2\n",
    "test = test[mask]\n",
    "predict = output[bkg_key]['prediction'][:,9:20,:]\n",
    "predict = predict.reshape(output[bkg_key]['prediction'].shape[0]*10,3)\n",
    "predict = predict[mask]\n",
    "plt.hist(test[:,0].flatten(), bins=bins_, alpha=0.5, label='X_test')\n",
    "plt.hist(predict[:,0].flatten(), bins=bins_, alpha=0.5, label='X_predict')\n",
    "plt.xlabel('Pi (GeV)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.yscale('log')\n",
    "plt.title('Jet pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee89cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss,max_loss=1e5,0\n",
    "min_tloss,max_tloss=1e5,0\n",
    "min_r,max_r=1e5,0\n",
    "min_kloss,max_kloss=1e5,0\n",
    "for key in output.keys():\n",
    "    if(key=='ZeroBias'): continue\n",
    "    if(np.min(output[key]['reco_loss'])<min_loss): min_loss = np.min(output[key]['reco_loss'])\n",
    "    if(np.mean(output[key]['reco_loss'])+10*np.std(output[key]['reco_loss'])>max_loss): max_loss = np.mean(output[key]['reco_loss'])+10*np.std(output[key]['reco_loss'])\n",
    "    \n",
    "    if(np.min(output[key]['total_loss'])<min_tloss): min_tloss = np.min(output[key]['total_loss'])\n",
    "    if(np.mean(output[key]['total_loss'])+10*np.std(output[key]['total_loss'])>max_tloss): max_tloss = np.mean(output[key]['total_loss'])+10*np.std(output[key]['total_loss'])\n",
    "    if(np.min(output[key]['radius'])<min_r): min_r = np.min(output[key]['radius'])\n",
    "    if(np.mean(output[key]['radius'])+10*np.std(output[key]['radius'])>max_r): max_r = np.mean(output[key]['radius'])+10*np.std(output[key]['radius'])\n",
    "    if(np.min(output[key]['kl_loss'])<min_kloss): min_kloss = np.min(output[key]['kl_loss'])\n",
    "    if(np.mean(output[key]['kl_loss'])+10*np.std(output[key]['kl_loss'])>max_kloss): max_kloss = np.mean(output[key]['kl_loss'])+10*np.std(output[key]['kl_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(output[key]['kl_loss'][np.isfinite(output[key]['kl_loss'])])+10*np.std(output[key]['kl_loss'][np.isfinite(output[key]['kl_loss'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c20ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_r = np.max(output[key]['radius'][np.isfinite(output[key]['radius'])])\n",
    "# max_kloss=np.max(output[key]['kl_loss'][np.isfinite(output[key]['kl_loss'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c97a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_loss,max_loss)\n",
    "print(min_tloss,max_tloss)\n",
    "print(min_r,max_r)\n",
    "print(min_kloss,max_kloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fee3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag='norm_test'\n",
    "bkg_key='ZeroBias'\n",
    "print(\"Plotting the results\")\n",
    "bins_=np.linspace(min_loss,1,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): plt.hist(output[key]['reco_loss'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['reco_loss'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Reco Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Loss distribution')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "bins_=np.linspace(min_tloss,160,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): plt.hist(output[key]['total_loss'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['total_loss'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Total Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Total Loss distribution')\n",
    "\n",
    "\n",
    "bins_=np.linspace(min_r,100000,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): plt.hist(output[key]['radius'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['radius'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Radius')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Radius distribution')\n",
    "\n",
    "\n",
    "bins_=np.linspace(min_kloss,160,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): plt.hist(output[key]['kl_loss'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['kl_loss'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('KL Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.title('KL distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make ROC curves\n",
    "bkg_key='ZeroBias'\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): continue\n",
    "    true_labels = np.concatenate((np.ones(output[key]['reco_loss'].shape[0]),np.zeros(output[bkg_key]['reco_loss'].shape[0])))\n",
    "    pred_labels = np.concatenate((output[key]['reco_loss'],output[bkg_key]['reco_loss']))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Reco Loss')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): continue\n",
    "    sig = output[key]['total_loss'][np.isfinite(output[key]['total_loss'])]\n",
    "    bkg = output[bkg_key]['total_loss'][np.isfinite(output[bkg_key]['total_loss'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Total Loss')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): continue\n",
    "    sig = output[key]['radius'][np.isfinite(output[key]['radius'])]\n",
    "    bkg = output[bkg_key]['radius'][np.isfinite(output[bkg_key]['radius'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Radius')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key): continue\n",
    "    sig = output[key]['kl_loss'][np.isfinite(output[key]['kl_loss'])]\n",
    "    bkg = output[bkg_key]['kl_loss'][np.isfinite(output[bkg_key]['kl_loss'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('KL Loss')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make ROC curves\n",
    "bkg_key='ZeroBias'\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key or key=='QCD'): continue\n",
    "    true_labels = np.concatenate((np.ones(output[key]['reco_loss'].shape[0]),np.zeros(output[bkg_key]['reco_loss'].shape[0])))\n",
    "    pred_labels = np.concatenate((output[key]['reco_loss'],output[bkg_key]['reco_loss']))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    rate = fpr*11245.6*2544/(10**6)\n",
    "    if('TT' in key): key_ = 'TTbar'\n",
    "    if('haa' in key): key_ = 'Higgs -> 4b'\n",
    "    if('HH' in key): key_ = 'SM HH -> 4b'\n",
    "    plt.plot(rate, tpr, label=key_+' (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 11245.6*2544/(10**6)], [0, 1], 'k--')\n",
    "plt.xlim([1e-6*11245.6*2544/(10**6), 11245.6*2544/(10**6)])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('Trigger Rate (MHz)')\n",
    "plt.ylabel('Signal Efficiency')\n",
    "plt.title('Reco Loss')\n",
    "plt.axvline(0.005, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key or key=='QCD'): continue\n",
    "    sig = output[key]['total_loss'][np.isfinite(output[key]['total_loss'])]\n",
    "    bkg = output[bkg_key]['total_loss'][np.isfinite(output[bkg_key]['total_loss'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    rate = fpr*11245.6*2544/(10**6)\n",
    "    if('TT' in key): key_ = 'TTbar'\n",
    "    if('haa' in key): key_ = 'Higgs -> 4b'\n",
    "    if('HH' in key): key_ = 'SM HH -> 4b'\n",
    "    plt.plot(rate, tpr, label=key_+' (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 11245.6*2544/(10**6)], [0, 1], 'k--')\n",
    "plt.xlim([1e-6*11245.6*2544/(10**6), 11245.6*2544/(10**6)])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('Trigger Rate (MHz)')\n",
    "plt.ylabel('Signal Efficiency')\n",
    "plt.title('Total Loss')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.005, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key or key=='QCD'): continue\n",
    "    sig = output[key]['radius'][np.isfinite(output[key]['radius'])]\n",
    "    bkg = output[bkg_key]['radius'][np.isfinite(output[bkg_key]['radius'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    rate = fpr*11245.6*2544/(10**6)\n",
    "    if('TT' in key): key_ = 'TTbar'\n",
    "    if('haa' in key): key_ = 'Higgs -> 4b'\n",
    "    if('HH' in key): key_ = 'SM HH -> 4b'\n",
    "    plt.plot(rate, tpr, label=key_+' (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 11245.6*2544/(10**6)], [0, 1], 'k--')\n",
    "plt.xlim([1e-6*11245.6*2544/(10**6), 11245.6*2544/(10**6)])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('Trigger Rate (MHz)')\n",
    "plt.ylabel('Signal Efficiency')\n",
    "plt.title('Radius')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.005, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key==bkg_key or key=='QCD'): continue\n",
    "    sig = output[key]['kl_loss'][np.isfinite(output[key]['kl_loss'])]\n",
    "    bkg = output[bkg_key]['kl_loss'][np.isfinite(output[bkg_key]['kl_loss'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    rate = fpr*11245.6*2544/(10**6)\n",
    "    if('TT' in key): key_ = 'TTbar'\n",
    "    if('haa' in key): key_ = 'Higgs -> 4b'\n",
    "    if('HH' in key): key_ = 'SM HH -> 4b'\n",
    "    plt.plot(rate, tpr, label=key_+' (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 11245.6*2544/(10**6)], [0, 1], 'k--')\n",
    "plt.xlim([1e-6*11245.6*2544/(10**6), 11245.6*2544/(10**6)])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('Trigger Rate (MHz)')\n",
    "plt.ylabel('Signal Efficiency')\n",
    "plt.title('KL Loss')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.005, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46460b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag='norm_test'\n",
    "print(\"Plotting the results\")\n",
    "bins_=np.linspace(min_loss,max_loss,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): plt.hist(output[key]['reco_loss'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['reco_loss'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Reco Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Loss distribution')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "bins_=np.linspace(min_tloss,max_tloss,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): plt.hist(output[key]['total_loss'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['total_loss'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Total Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Total Loss distribution')\n",
    "\n",
    "\n",
    "bins_=np.linspace(min_r,max_r,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): plt.hist(output[key]['radius'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['radius'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Radius')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Radius distribution')\n",
    "\n",
    "\n",
    "bins_=np.linspace(min_kloss,max_kloss,100)\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): plt.hist(output[key]['kl_loss'],label=key,histtype='step',bins=bins_,color='black',linewidth=2,density=True)\n",
    "    else: plt.hist(output[key]['kl_loss'],label=key,histtype='step',bins=bins_,density=True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('KL Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.title('KL distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make ROC curves\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): continue\n",
    "    true_labels = np.concatenate((np.ones(output[key]['reco_loss'].shape[0]),np.zeros(output['qcd']['reco_loss'].shape[0])))\n",
    "    pred_labels = np.concatenate((output[key]['reco_loss'],output['qcd']['reco_loss']))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Reco Loss')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): continue\n",
    "    true_labels = np.concatenate((np.ones(output[key]['total_loss'].shape[0]),np.zeros(output['qcd']['total_loss'].shape[0])))\n",
    "    pred_labels = np.concatenate((output[key]['total_loss'],output['qcd']['total_loss']))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Total Loss')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): continue\n",
    "    sig = output[key]['radius'][np.isfinite(output[key]['radius'])]\n",
    "    bkg = output['qcd']['radius'][np.isfinite(output['qcd']['radius'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Radius')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for key in output.keys():\n",
    "    if(key=='qcd'): continue\n",
    "    sig = output[key]['kl_loss'][np.isfinite(output[key]['kl_loss'])]\n",
    "    bkg = output['qcd']['kl_loss'][np.isfinite(output['qcd']['kl_loss'])]\n",
    "    true_labels = np.concatenate((np.ones(sig.shape[0]),np.zeros(bkg.shape[0])))\n",
    "    pred_labels = np.concatenate((sig,bkg))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([1e-6, 1.0])\n",
    "plt.ylim([1e-6, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('KL Loss')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(0.000125, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee1d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5306c70f55a6581beeec0479c83a62bc04e55e275d80ee3f1046f39948a13be6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

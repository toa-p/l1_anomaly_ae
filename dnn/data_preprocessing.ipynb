{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from functions import prepare_data\n",
    "\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file='/eos/project/d/dshep/L1anomaly/QCD_preprocessed.h5'\n",
    "bsm_file = '/eos/project/d/dshep/L1anomaly/BSM_preprocessed.h5'\n",
    "output_file='/eos/project/d/dshep/L1anomaly/CMS_QCD_data_flatten.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(input_file, input_bsm, output_file, events=20000000):\n",
    "    # read QCD data\n",
    "    with h5py.File(input_file, 'r') as h5f:\n",
    "        # remove last feature, which is the type of particle\n",
    "        data = h5f['full_data_cyl'][:events,:,:]\n",
    "        #np.random.shuffle(data)\n",
    "        #data = data[:events,:,:]\n",
    "    \n",
    "    # fit scaler to the full data\n",
    "    pt_scaler = StandardScaler()\n",
    "    data_target = np.copy(data)\n",
    "    data_target[:,:,0] = pt_scaler.fit_transform(data_target[:,:,0])\n",
    "    data_target[:,:,0] = np.multiply(data_target[:,:,0], np.not_equal(data[:,:,0],0))\n",
    "\n",
    "    data = data.reshape((data.shape[0],57))\n",
    "    data_target = data_target.reshape((data_target.shape[0],57))\n",
    "    # define training, test and validation datasets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=0.5)\n",
    "    del data, data_target\n",
    "    \n",
    "    # read BSM data\n",
    "    bsm_data = []\n",
    "    \n",
    "    with h5py.File(input_bsm,'r') as h5f2:\n",
    "        for key in h5f2.keys():\n",
    "            bsm_file = h5f[key][:,:,:]\n",
    "            bsm_file = bsm_file.reshape(bsm_file.shape[0],bsm_file.shape[1]*bsm_file.shape[2])\n",
    "            bsm_data.append(bsm)\n",
    "    \n",
    "    bsm_scaled_data=[]\n",
    "    for bsm in bsm_data:\n",
    "        bsm = bsm.reshape(bsm.shape[0],19,3,1)\n",
    "        bsm = np.squeeze(bsm, axis=-1)\n",
    "        bsm_data_target = np.copy(bsm)\n",
    "        bsm_data_target[:,:,0] = pt_scaler.transform(bsm_data_target[:,:,0])\n",
    "        bsm_data_target[:,:,0] = np.multiply(bsm_data_target[:,:,0], np.not_equal(bsm[:,:,0],0))\n",
    "        bsm_data_target.reshape(bsm_data_target.shape[0], bsm_data_target.shape[1]*bsm_data_target.shape[2])\n",
    "        bsm_scaled_data.append(bsm_data_target)\n",
    "    \n",
    "    data = [X_train, Y_train, X_test, Y_test, bsm_data, bsm_scaled_data, pt_scaler]\n",
    "\n",
    "    with open(output_file, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = 20000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = tfio.IODataset.from_hdf5(input_file, '/full_data_cyl')\n",
    "# data = data.take(NUMSAMPLES).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(input_file, bsm_file, output_file, events=20000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-terminal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

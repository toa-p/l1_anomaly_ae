Model: "encoder"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 57)]         0           []                               
                                                                                                  
 batch_normalization (BatchNorm  (None, 57)          228         ['input_1[0][0]']                
 alization)                                                                                       
                                                                                                  
 dense (Dense)                  (None, 32)           1856        ['batch_normalization[0][0]']    
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 32)          128         ['dense[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 32)           0           ['batch_normalization_1[0][0]']  
                                                                                                  
 dense_1 (Dense)                (None, 16)           528         ['leaky_re_lu[0][0]']            
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 16)          64          ['dense_1[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 16)           0           ['batch_normalization_2[0][0]']  
                                                                                                  
 latent_mu (Dense)              (None, 7)            119         ['leaky_re_lu_1[0][0]']          
                                                                                                  
 latent_logvar (Dense)          (None, 7)            119         ['leaky_re_lu_1[0][0]']          
                                                                                                  
 sampling (Sampling)            (None, 7)            0           ['latent_mu[0][0]',              
                                                                  'latent_logvar[0][0]']          
                                                                                                  
==================================================================================================
Total params: 3,042
Trainable params: 2,832
Non-trainable params: 210
__________________________________________________________________________________________________
Model: "decoder"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 decoder_input (InputLayer)  [(None, 7)]               0         
                                                                 
 dense_2 (Dense)             (None, 16)                128       
                                                                 
 batch_normalization_3 (Batc  (None, 16)               64        
 hNormalization)                                                 
                                                                 
 leaky_re_lu_2 (LeakyReLU)   (None, 16)                0         
                                                                 
 dense_3 (Dense)             (None, 32)                544       
                                                                 
 batch_normalization_4 (Batc  (None, 32)               128       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         
                                                                 
 dense_4 (Dense)             (None, 57)                1881      
                                                                 
=================================================================
Total params: 2,745
Trainable params: 2,649
Non-trainable params: 96
_________________________________________________________________
Training the model
Epoch 1/150
   4/1954 [..............................] - ETA: 14:01 - loss: 2.0995 - reconstruction_loss: 0.5827 - kl_loss: 1.9269Batch 4: Invalid loss, terminating training
1954/1954 [==============================] - 113s 54ms/step - loss: inf - reconstruction_loss: 0.5631 - kl_loss: inf - val_loss: nan - val_reconstruction_loss: nan - val_kl_loss: inf - lr: 0.0010